{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Saving a Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3lvlwafr2o6BykItGxmhJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeong01/hyeong01.github.io/blob/master/example_code_stoarge/Saving_a_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJl5c5dUT65c"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI8JnnCEUBCc",
        "outputId": "a7ab39d0-3868-4d54-a1dc-424870c0c009"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBXIs0l6XUNZ"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=0),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16,32,kernel_size=3,stride=2,padding=0),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=0),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "        \n",
        "        self.drop_out = nn.Dropout()\n",
        "        self.fc1 = nn.Linear(3*3*64, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hfQ5901e50Y"
      },
      "source": [
        "model = Model()\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.1, momentum=0.9)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58l47o0gfRLK",
        "outputId": "cdff6c02-4577-4a9c-d15c-30e7a4999647"
      },
      "source": [
        "print(\"Model state:\")\n",
        "for param in model.state_dict():\n",
        "    print(param, \"   \", model.state_dict()[param].size())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model state:\n",
            "layer1.0.weight     torch.Size([16, 3, 3, 3])\n",
            "layer1.0.bias     torch.Size([16])\n",
            "layer1.1.weight     torch.Size([16])\n",
            "layer1.1.bias     torch.Size([16])\n",
            "layer1.1.running_mean     torch.Size([16])\n",
            "layer1.1.running_var     torch.Size([16])\n",
            "layer1.1.num_batches_tracked     torch.Size([])\n",
            "layer2.0.weight     torch.Size([32, 16, 3, 3])\n",
            "layer2.0.bias     torch.Size([32])\n",
            "layer2.1.weight     torch.Size([32])\n",
            "layer2.1.bias     torch.Size([32])\n",
            "layer2.1.running_mean     torch.Size([32])\n",
            "layer2.1.running_var     torch.Size([32])\n",
            "layer2.1.num_batches_tracked     torch.Size([])\n",
            "layer3.0.weight     torch.Size([64, 32, 3, 3])\n",
            "layer3.0.bias     torch.Size([64])\n",
            "layer3.1.weight     torch.Size([64])\n",
            "layer3.1.bias     torch.Size([64])\n",
            "layer3.1.running_mean     torch.Size([64])\n",
            "layer3.1.running_var     torch.Size([64])\n",
            "layer3.1.num_batches_tracked     torch.Size([])\n",
            "fc1.weight     torch.Size([1000, 576])\n",
            "fc1.bias     torch.Size([1000])\n",
            "fc2.weight     torch.Size([1, 1000])\n",
            "fc2.bias     torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmBQPu01f6GK",
        "outputId": "3757f88d-ebda-4492-d30e-a9dbe68f89f1"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3,224,224))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 111, 111]             448\n",
            "       BatchNorm2d-2         [-1, 16, 111, 111]              32\n",
            "              ReLU-3         [-1, 16, 111, 111]               0\n",
            "         MaxPool2d-4           [-1, 16, 55, 55]               0\n",
            "            Conv2d-5           [-1, 32, 27, 27]           4,640\n",
            "       BatchNorm2d-6           [-1, 32, 27, 27]              64\n",
            "              ReLU-7           [-1, 32, 27, 27]               0\n",
            "         MaxPool2d-8           [-1, 32, 13, 13]               0\n",
            "            Conv2d-9             [-1, 64, 6, 6]          18,496\n",
            "      BatchNorm2d-10             [-1, 64, 6, 6]             128\n",
            "             ReLU-11             [-1, 64, 6, 6]               0\n",
            "        MaxPool2d-12             [-1, 64, 3, 3]               0\n",
            "          Dropout-13                  [-1, 576]               0\n",
            "           Linear-14                 [-1, 1000]         577,000\n",
            "           Linear-15                    [-1, 1]           1,001\n",
            "================================================================\n",
            "Total params: 601,809\n",
            "Trainable params: 601,809\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 5.53\n",
            "Params size (MB): 2.30\n",
            "Estimated Total Size (MB): 8.40\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggzhyRpbjXi3"
      },
      "source": [
        "# save parameter\n",
        "MODEL_PATH = \"saved_models\"\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    os.makedirs(MODEL_PATH)\n",
        "torch.save(model.state_dict(), os.path.join(MODEL_PATH, \"model.pt\"))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JECYKFq_h6_R",
        "outputId": "c4864929-2d2c-4cf0-9f5c-9bad138d10a9"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "another_model = Model()\n",
        "another_model.load_state_dict(torch.load(os.path.join(MODEL_PATH, 'model.pt')))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hNCdpNlkRv4",
        "outputId": "fbe9d36e-58d2-4165-975c-20999111a35f"
      },
      "source": [
        "# save whole model\n",
        "torch.save(model, os.path.join(MODEL_PATH, \"whole_model.pt\"))\n",
        "model = torch.load(os.path.join(MODEL_PATH, \"whole_model.pt\"))\n",
        "model.eval()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (drop_out): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=576, out_features=1000, bias=True)\n",
              "  (fc2): Linear(in_features=1000, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}